# Symple-Maze

「Day1 強化学習の位置づけを知る」 の、簡単な迷路の実装。

## MDPの整理

MDP(マルコフ決定過程)：

- s : 状態(State)
- a : 行動(Action)
- T : 状態遷移の確率(遷移関数)。状態と行動を引数に、遷移先(次の状態)と遷移確率を出力する関数。
- R : 即時報酬(報酬関数)。状態と遷移先を引数に、報酬を出力する関数(行動を引数に取る場合もある)。
  
  
今回実装する迷路の環境におけるMDPを整理すると、

- s : セルの位置
- a : 上下左右への移動
- T : 状態と行動を受け取り、移動可能なセルとそこへ移動する確率(遷移確率)を返す関数
- R : 状態を受け取り、ゴールのセルなら1を、ドボンのセルなら-1を返す関数

## コードについて

- State() ・・・ 状態を表現するクラス
- Action() ・・・ 行動を表現するクラス
- Environment() ・・・ 環境(=迷路)の実態を表現するクラス
- transit_func() ・・・ 遷移関数  
決定した行動以外の方向に進む確率を設定する
- reward_func() ・・・ 報酬関数  
今回は遷移先の状態でのみ報酬が決まるため、状態のみを引数に取る